{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '002'\n",
      "run_time: base\n",
      "data:\n",
      "  input_root: ../../data/input\n",
      "  train_path: ../../data/input/train.csv\n",
      "  test_path: ../../data/input/test.csv\n",
      "  sample_submission_path: ../../data/input/sample_submission.csv\n",
      "  mapping_path: ../../data/input/misconception_mapping.csv\n",
      "  mapping_meta_path: ../../data/input/mapping_meta.parquet\n",
      "  output_root: ../../data/output\n",
      "  results_root: ../../results\n",
      "  results_path: ../../results/002/base\n",
      "seed: 42\n",
      "k: 25\n",
      "model:\n",
      "  model_name: dunzhang/stella_en_400M_v5\n",
      "  epoch: 2\n",
      "  lr: 2.0e-05\n",
      "  batch_size: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pytz\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from omegaconf import OmegaConf\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from src.config import cfg\n",
    "from src.data import add_subject_name_info, preprocess_train\n",
    "from src.dir import create_dir\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.model.model_name = \"dunzhang/stella_en_400M_v5\"\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "mapping = pl.read_csv(cfg.data.mapping_path, try_parse_dates=True)\n",
    "mapping_meta = pl.read_parquet(cfg.data.mapping_meta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations toâ€¦</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do â€¦</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order oâ€¦</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fractionâ€¦</td><td>&quot;Simplifying Algebraic Fractionâ€¦</td><td>&quot;Simplify the following, if posâ€¦</td><td>&quot;B&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( t \\)&quot;</td><td>&quot;ConstructName: Simplify an algâ€¦</td><td>&quot;A&quot;</td><td>&quot;1000_A&quot;</td><td>891</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fractionâ€¦</td><td>&quot;Simplifying Algebraic Fractionâ€¦</td><td>&quot;Simplify the following, if posâ€¦</td><td>&quot;B&quot;</td><td>&quot;AnswerCText&quot;</td><td>&quot;\\( 1 \\)&quot;</td><td>&quot;ConstructName: Simplify an algâ€¦</td><td>&quot;C&quot;</td><td>&quot;1000_C&quot;</td><td>891</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fractionâ€¦</td><td>&quot;Simplifying Algebraic Fractionâ€¦</td><td>&quot;Simplify the following, if posâ€¦</td><td>&quot;B&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not simplify&quot;</td><td>&quot;ConstructName: Simplify an algâ€¦</td><td>&quot;D&quot;</td><td>&quot;1000_D&quot;</td><td>353</td></tr><tr><td>1001</td><td>&quot;Round numbers to two decimal pâ€¦</td><td>&quot;Rounding to Decimal Places&quot;</td><td>&quot;What is \\( \\mathbf{3 . 5 1 6 3â€¦</td><td>&quot;B&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( 3.51 \\)&quot;</td><td>&quot;ConstructName: Round numbers tâ€¦</td><td>&quot;A&quot;</td><td>&quot;1001_A&quot;</td><td>1379</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ QuestionI â”† Construct â”† SubjectNa â”† QuestionT â”† â€¦ â”† AllText   â”† AnswerAlp â”† QuestionI â”† Misconce â”‚\n",
       "â”‚ d         â”† Name      â”† me        â”† ext       â”†   â”† ---       â”† habet     â”† d_Answer  â”† ptionId  â”‚\n",
       "â”‚ ---       â”† ---       â”† ---       â”† ---       â”†   â”† str       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ i64       â”† str       â”† str       â”† str       â”†   â”†           â”† str       â”† str       â”† i64      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0         â”† Use the   â”† BIDMAS    â”† \\[        â”† â€¦ â”† Construct â”† D         â”† 0_D       â”† 1672     â”‚\n",
       "â”‚           â”† order of  â”†           â”† 3 \\times  â”†   â”† Name: Use â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† operation â”†           â”† 2+4-5     â”†   â”† the order â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† s toâ€¦     â”†           â”† \\]        â”†   â”† oâ€¦        â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† Where do  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† â€¦         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 1000      â”† Simplify  â”† Simplifyi â”† Simplify  â”† â€¦ â”† Construct â”† A         â”† 1000_A    â”† 891      â”‚\n",
       "â”‚           â”† an        â”† ng        â”† the follo â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† algebraic â”† Algebraic â”† wing, if  â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fractionâ€¦ â”† Fractionâ€¦ â”† posâ€¦      â”†   â”† an algâ€¦   â”†           â”†           â”†          â”‚\n",
       "â”‚ 1000      â”† Simplify  â”† Simplifyi â”† Simplify  â”† â€¦ â”† Construct â”† C         â”† 1000_C    â”† 891      â”‚\n",
       "â”‚           â”† an        â”† ng        â”† the follo â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† algebraic â”† Algebraic â”† wing, if  â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fractionâ€¦ â”† Fractionâ€¦ â”† posâ€¦      â”†   â”† an algâ€¦   â”†           â”†           â”†          â”‚\n",
       "â”‚ 1000      â”† Simplify  â”† Simplifyi â”† Simplify  â”† â€¦ â”† Construct â”† D         â”† 1000_D    â”† 353      â”‚\n",
       "â”‚           â”† an        â”† ng        â”† the follo â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† algebraic â”† Algebraic â”† wing, if  â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fractionâ€¦ â”† Fractionâ€¦ â”† posâ€¦      â”†   â”† an algâ€¦   â”†           â”†           â”†          â”‚\n",
       "â”‚ 1001      â”† Round     â”† Rounding  â”† What is   â”† â€¦ â”† Construct â”† A         â”† 1001_A    â”† 1379     â”‚\n",
       "â”‚           â”† numbers   â”† to        â”† \\(        â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† to two    â”† Decimal   â”† \\mathbf{3 â”†   â”† Round     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† decimal   â”† Places    â”† . 5 1 6   â”†   â”† numbers   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† pâ€¦        â”†           â”† 3â€¦        â”†   â”† tâ€¦        â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainã®å‰å‡¦ç†\n",
    "train_long = preprocess_train(train)\n",
    "train_long.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>MisconceptionId</th><th>MisconceptionName</th><th>SubjectNames</th><th>MisconceptionName_with_SubjectNames</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Does not know that angles in aâ€¦</td><td>[&quot;Angles in Triangles&quot;]</td><td>&quot;The misconception &#x27;Does not knâ€¦</td></tr><tr><td>1</td><td>&quot;Uses dividing fractions methodâ€¦</td><td>[&quot;Multiplying Fractions&quot;, &quot;Multiplying and Dividing Negative Numbers&quot;]</td><td>&quot;The misconception &#x27;Uses dividiâ€¦</td></tr><tr><td>2</td><td>&quot;Believes there are 100 degreesâ€¦</td><td>[&quot;Measuring Angles&quot;, &quot;Types, Naming and Estimating&quot;]</td><td>&quot;The misconception &#x27;Believes thâ€¦</td></tr><tr><td>3</td><td>&quot;Thinks a quadratic without a nâ€¦</td><td>[&quot;Factorising into a Single Bracket&quot;]</td><td>&quot;The misconception &#x27;Thinks a quâ€¦</td></tr><tr><td>4</td><td>&quot;Believes addition of terms andâ€¦</td><td>[&quot;Simplifying Expressions by Collecting Like Terms&quot;]</td><td>&quot;The misconception &#x27;Believes adâ€¦</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ MisconceptionId â”† MisconceptionName        â”† SubjectNames             â”† MisconceptionName_with_S â”‚\n",
       "â”‚ ---             â”† ---                      â”† ---                      â”† ubjectâ€¦                  â”‚\n",
       "â”‚ i64             â”† str                      â”† list[str]                â”† ---                      â”‚\n",
       "â”‚                 â”†                          â”†                          â”† str                      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0               â”† Does not know that       â”† [\"Angles in Triangles\"]  â”† The misconception 'Does  â”‚\n",
       "â”‚                 â”† angles in aâ€¦             â”†                          â”† not knâ€¦                  â”‚\n",
       "â”‚ 1               â”† Uses dividing fractions  â”† [\"Multiplying            â”† The misconception 'Uses  â”‚\n",
       "â”‚                 â”† methodâ€¦                  â”† Fractions\", \"Mulâ€¦        â”† dividiâ€¦                  â”‚\n",
       "â”‚ 2               â”† Believes there are 100   â”† [\"Measuring Angles\",     â”† The misconception        â”‚\n",
       "â”‚                 â”† degreesâ€¦                 â”† \"Types, Nâ€¦               â”† 'Believes thâ€¦            â”‚\n",
       "â”‚ 3               â”† Thinks a quadratic       â”† [\"Factorising into a     â”† The misconception        â”‚\n",
       "â”‚                 â”† without a nâ€¦             â”† Single Brâ€¦               â”† 'Thinks a quâ€¦            â”‚\n",
       "â”‚ 4               â”† Believes addition of     â”† [\"Simplifying            â”† The misconception        â”‚\n",
       "â”‚                 â”† terms andâ€¦               â”† Expressions by Câ€¦        â”† 'Believes adâ€¦            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainã®SubjectNameæƒ…å ±ã‚’mappingã«è¿½åŠ \n",
    "mapping_meta = add_subject_name_info(train, mapping)\n",
    "mapping_meta.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4370, 1024) (2587, 1024)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(cfg.model.model_name, trust_remote_code=True)\n",
    "\n",
    "train_long_vec = model.encode(train_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "misconception_mapping_vec = model.encode(\n",
    "    mapping_meta[\"MisconceptionName_with_SubjectNames\"].to_list(), normalize_embeddings=True\n",
    ")\n",
    "print(train_long_vec.shape, misconception_mapping_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cos_sim_arr.shape: (4370, 2587)\n",
      "[0.40005112 0.5154699  0.32225215 ... 0.39596674 0.54062563 0.60524815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_sorted_indices.shape: (4370, 2587)\n",
      "[2488 2532  577 ... 1699  453 1414]\n"
     ]
    }
   ],
   "source": [
    "# ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—\n",
    "train_cos_sim_arr = cosine_similarity(train_long_vec, misconception_mapping_vec)\n",
    "print(f\"train_cos_sim_arr.shape: {train_cos_sim_arr.shape}\")\n",
    "print(train_cos_sim_arr[0])\n",
    "\n",
    "# ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒé™é †ã«ãªã‚‹ã‚ˆã†ã«å„è¡Œã‚’ã‚½ãƒ¼ãƒˆ\n",
    "train_sorted_indices = np.argsort(-train_cos_sim_arr, axis=1)\n",
    "print(f\"\\ntrain_sorted_indices.shape: {train_sorted_indices.shape}\")\n",
    "print(train_sorted_indices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th><th>PredictMisconceptionId</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations toâ€¦</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do â€¦</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order oâ€¦</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>[2488, 2532, â€¦ 1413]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 12)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ QuestionI â”† Construct â”† SubjectNa â”† QuestionT â”† â€¦ â”† AnswerAlp â”† QuestionI â”† Misconcep â”† PredictM â”‚\n",
       "â”‚ d         â”† Name      â”† me        â”† ext       â”†   â”† habet     â”† d_Answer  â”† tionId    â”† isconcep â”‚\n",
       "â”‚ ---       â”† ---       â”† ---       â”† ---       â”†   â”† ---       â”† ---       â”† ---       â”† tionId   â”‚\n",
       "â”‚ i64       â”† str       â”† str       â”† str       â”†   â”† str       â”† str       â”† i64       â”† ---      â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”† list[i64 â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”† ]        â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0         â”† Use the   â”† BIDMAS    â”† \\[        â”† â€¦ â”† D         â”† 0_D       â”† 1672      â”† [2488,   â”‚\n",
       "â”‚           â”† order of  â”†           â”† 3 \\times  â”†   â”†           â”†           â”†           â”† 2532, â€¦  â”‚\n",
       "â”‚           â”† operation â”†           â”† 2+4-5     â”†   â”†           â”†           â”†           â”† 1413]    â”‚\n",
       "â”‚           â”† s toâ€¦     â”†           â”† \\]        â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† Where do  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† â€¦         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_long = train_long.with_columns(\n",
    "    pl.Series(train_sorted_indices[:, : cfg.k].tolist()).alias(\"PredictMisconceptionId\")\n",
    ")\n",
    "train_long.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_587, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PredictMisconceptionId</th><th>PredictMisconceptionName</th><th>PredictSubjectNames</th><th>PredictMisconceptionName_with_SubjectNames</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Does not know that angles in aâ€¦</td><td>[&quot;Angles in Triangles&quot;]</td><td>&quot;The misconception &#x27;Does not knâ€¦</td></tr><tr><td>1</td><td>&quot;Uses dividing fractions methodâ€¦</td><td>[&quot;Multiplying Fractions&quot;, &quot;Multiplying and Dividing Negative Numbers&quot;]</td><td>&quot;The misconception &#x27;Uses dividiâ€¦</td></tr><tr><td>2</td><td>&quot;Believes there are 100 degreesâ€¦</td><td>[&quot;Measuring Angles&quot;, &quot;Types, Naming and Estimating&quot;]</td><td>&quot;The misconception &#x27;Believes thâ€¦</td></tr><tr><td>3</td><td>&quot;Thinks a quadratic without a nâ€¦</td><td>[&quot;Factorising into a Single Bracket&quot;]</td><td>&quot;The misconception &#x27;Thinks a quâ€¦</td></tr><tr><td>4</td><td>&quot;Believes addition of terms andâ€¦</td><td>[&quot;Simplifying Expressions by Collecting Like Terms&quot;]</td><td>&quot;The misconception &#x27;Believes adâ€¦</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2582</td><td>&quot;When multiplying numbers with â€¦</td><td>[]</td><td>&quot;The misconception is: When mulâ€¦</td></tr><tr><td>2583</td><td>&quot;Does not know what a cube numbâ€¦</td><td>[&quot;Squares, Cubes, etc&quot;, &quot;Square Roots, Cube Roots, etc&quot;]</td><td>&quot;The misconception &#x27;Does not knâ€¦</td></tr><tr><td>2584</td><td>&quot;Believes that any percentage oâ€¦</td><td>[]</td><td>&quot;The misconception is: Believesâ€¦</td></tr><tr><td>2585</td><td>&quot;Believes a cubic expression shâ€¦</td><td>[&quot;Expanding Triple Brackets and more&quot;]</td><td>&quot;The misconception &#x27;Believes a â€¦</td></tr><tr><td>2586</td><td>&quot;Misunderstands order of operatâ€¦</td><td>[&quot;Rearranging Formula and Equations&quot;]</td><td>&quot;The misconception &#x27;Misunderstaâ€¦</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_587, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ PredictMisconceptionId â”† PredictMisconceptionNa â”† PredictSubjectNames    â”† PredictMisconceptionN â”‚\n",
       "â”‚ ---                    â”† me                     â”† ---                    â”† ame_with_â€¦            â”‚\n",
       "â”‚ i64                    â”† ---                    â”† list[str]              â”† ---                   â”‚\n",
       "â”‚                        â”† str                    â”†                        â”† str                   â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0                      â”† Does not know that     â”† [\"Angles in            â”† The misconception     â”‚\n",
       "â”‚                        â”† angles in aâ€¦           â”† Triangles\"]            â”† 'Does not knâ€¦         â”‚\n",
       "â”‚ 1                      â”† Uses dividing          â”† [\"Multiplying          â”† The misconception     â”‚\n",
       "â”‚                        â”† fractions methodâ€¦      â”† Fractions\", \"Mulâ€¦      â”† 'Uses dividiâ€¦         â”‚\n",
       "â”‚ 2                      â”† Believes there are 100 â”† [\"Measuring Angles\",   â”† The misconception     â”‚\n",
       "â”‚                        â”† degreesâ€¦               â”† \"Types, Nâ€¦             â”† 'Believes thâ€¦         â”‚\n",
       "â”‚ 3                      â”† Thinks a quadratic     â”† [\"Factorising into a   â”† The misconception     â”‚\n",
       "â”‚                        â”† without a nâ€¦           â”† Single Brâ€¦             â”† 'Thinks a quâ€¦         â”‚\n",
       "â”‚ 4                      â”† Believes addition of   â”† [\"Simplifying          â”† The misconception     â”‚\n",
       "â”‚                        â”† terms andâ€¦             â”† Expressions by Câ€¦      â”† 'Believes adâ€¦         â”‚\n",
       "â”‚ â€¦                      â”† â€¦                      â”† â€¦                      â”† â€¦                     â”‚\n",
       "â”‚ 2582                   â”† When multiplying       â”† []                     â”† The misconception is: â”‚\n",
       "â”‚                        â”† numbers with â€¦         â”†                        â”† When mulâ€¦             â”‚\n",
       "â”‚ 2583                   â”† Does not know what a   â”† [\"Squares, Cubes,      â”† The misconception     â”‚\n",
       "â”‚                        â”† cube numbâ€¦             â”† etc\", \"Squarâ€¦          â”† 'Does not knâ€¦         â”‚\n",
       "â”‚ 2584                   â”† Believes that any      â”† []                     â”† The misconception is: â”‚\n",
       "â”‚                        â”† percentage oâ€¦          â”†                        â”† Believesâ€¦             â”‚\n",
       "â”‚ 2585                   â”† Believes a cubic       â”† [\"Expanding Triple     â”† The misconception     â”‚\n",
       "â”‚                        â”† expression shâ€¦         â”† Brackets anâ€¦           â”† 'Believes a â€¦         â”‚\n",
       "â”‚ 2586                   â”† Misunderstands order   â”† [\"Rearranging Formula  â”† The misconception     â”‚\n",
       "â”‚                        â”† of operatâ€¦             â”† and Equaâ€¦              â”† 'Misunderstaâ€¦         â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_meta.rename(lambda x: \"Predict\" + x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th><th>PredictMisconceptionId</th><th>MisconceptionName</th><th>SubjectNames</th><th>MisconceptionName_with_SubjectNames</th><th>PredictMisconceptionName</th><th>PredictSubjectNames</th><th>PredictMisconceptionName_with_SubjectNames</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>list[str]</td><td>str</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations toâ€¦</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do â€¦</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order oâ€¦</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>2488</td><td>&quot;Confuses the order of operatioâ€¦</td><td>[&quot;BIDMAS&quot;]</td><td>&quot;The misconception &#x27;Confuses thâ€¦</td><td>&quot;Answers order of operations quâ€¦</td><td>[&quot;Function Machines&quot;, &quot;Multiplying and Dividing Algebraic Fractions&quot;, â€¦ &quot;Substitution into Formula&quot;]</td><td>&quot;The misconception &#x27;Answers ordâ€¦</td></tr><tr><td>0</td><td>&quot;Use the order of operations toâ€¦</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do â€¦</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order oâ€¦</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>2532</td><td>&quot;Confuses the order of operatioâ€¦</td><td>[&quot;BIDMAS&quot;]</td><td>&quot;The misconception &#x27;Confuses thâ€¦</td><td>&quot;Believes order of operations dâ€¦</td><td>[&quot;Plotting Quadratics from Tables of Values&quot;, &quot;BIDMAS&quot;]</td><td>&quot;The misconception &#x27;Believes orâ€¦</td></tr><tr><td>0</td><td>&quot;Use the order of operations toâ€¦</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do â€¦</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order oâ€¦</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>577</td><td>&quot;Confuses the order of operatioâ€¦</td><td>[&quot;BIDMAS&quot;]</td><td>&quot;The misconception &#x27;Confuses thâ€¦</td><td>&quot;Does not realise multiplying aâ€¦</td><td>[&quot;Factorising into a Single Bracket&quot;, &quot;Expanding Single Brackets&quot;]</td><td>&quot;The misconception &#x27;Does not reâ€¦</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 18)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ QuestionI â”† Construct â”† SubjectNa â”† QuestionT â”† â€¦ â”† Misconcep â”† PredictMi â”† PredictSu â”† PredictM â”‚\n",
       "â”‚ d         â”† Name      â”† me        â”† ext       â”†   â”† tionName_ â”† sconcepti â”† bjectName â”† isconcep â”‚\n",
       "â”‚ ---       â”† ---       â”† ---       â”† ---       â”†   â”† with_Subj â”† onName    â”† s         â”† tionName â”‚\n",
       "â”‚ i64       â”† str       â”† str       â”† str       â”†   â”† ectâ€¦      â”† ---       â”† ---       â”† _with_â€¦  â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ---       â”† str       â”† list[str] â”† ---      â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† str       â”†           â”†           â”† str      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0         â”† Use the   â”† BIDMAS    â”† \\[        â”† â€¦ â”† The misco â”† Answers   â”† [\"Functio â”† The misc â”‚\n",
       "â”‚           â”† order of  â”†           â”† 3 \\times  â”†   â”† nception  â”† order of  â”† n Machine â”† onceptio â”‚\n",
       "â”‚           â”† operation â”†           â”† 2+4-5     â”†   â”† 'Confuses â”† operation â”† s\",       â”† n        â”‚\n",
       "â”‚           â”† s toâ€¦     â”†           â”† \\]        â”†   â”† thâ€¦       â”† s quâ€¦     â”† \"Multiplâ€¦ â”† 'Answers â”‚\n",
       "â”‚           â”†           â”†           â”† Where do  â”†   â”†           â”†           â”†           â”† ordâ€¦     â”‚\n",
       "â”‚           â”†           â”†           â”† â€¦         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 0         â”† Use the   â”† BIDMAS    â”† \\[        â”† â€¦ â”† The misco â”† Believes  â”† [\"Plottin â”† The misc â”‚\n",
       "â”‚           â”† order of  â”†           â”† 3 \\times  â”†   â”† nception  â”† order of  â”† g Quadrat â”† onceptio â”‚\n",
       "â”‚           â”† operation â”†           â”† 2+4-5     â”†   â”† 'Confuses â”† operation â”† ics from  â”† n 'Belie â”‚\n",
       "â”‚           â”† s toâ€¦     â”†           â”† \\]        â”†   â”† thâ€¦       â”† s dâ€¦      â”† Tabâ€¦      â”† ves orâ€¦  â”‚\n",
       "â”‚           â”†           â”†           â”† Where do  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† â€¦         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 0         â”† Use the   â”† BIDMAS    â”† \\[        â”† â€¦ â”† The misco â”† Does not  â”† [\"Factori â”† The misc â”‚\n",
       "â”‚           â”† order of  â”†           â”† 3 \\times  â”†   â”† nception  â”† realise   â”† sing into â”† onceptio â”‚\n",
       "â”‚           â”† operation â”†           â”† 2+4-5     â”†   â”† 'Confuses â”† multiplyi â”† a Single  â”† n 'Does  â”‚\n",
       "â”‚           â”† s toâ€¦     â”†           â”† \\]        â”†   â”† thâ€¦       â”† ng aâ€¦     â”† Brâ€¦       â”† not reâ€¦  â”‚\n",
       "â”‚           â”†           â”†           â”† Where do  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† â€¦         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_retrieved.shape: (105725, 18)\n"
     ]
    }
   ],
   "source": [
    "train_retrieved = (\n",
    "    train_long.explode(\"PredictMisconceptionId\")\n",
    "    .join(mapping_meta, on=\"MisconceptionId\")\n",
    "    .join(mapping_meta.rename(lambda x: \"Predict\" + x), on=\"PredictMisconceptionId\")\n",
    "    # MisconceptionIdã¨PredictMisconceptionIdãŒåŒã˜è¡Œï¼ˆæ­£è§£ã—ã¦ã‚‹ã‚‚ã®ï¼‰ã‚’å‰Šé™¤\n",
    "    .filter(pl.col(\"MisconceptionId\") != pl.col(\"PredictMisconceptionId\"))\n",
    ")\n",
    "display(train_retrieved.head(3))\n",
    "print(f\"train_retrieved.shape: {train_retrieved.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AllText', 'AnswerAlphabet', 'QuestionId_Answer', 'MisconceptionId', 'PredictMisconceptionId', 'MisconceptionName', 'SubjectNames', 'MisconceptionName_with_SubjectNames', 'PredictMisconceptionName', 'PredictSubjectNames', 'PredictMisconceptionName_with_SubjectNames'],\n",
       "    num_rows: 105725\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_polars(train_retrieved)\n",
    "train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train_dataset = train_dataset.select(range(500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ../../results/002/20241113_125904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_bf16_supported()=True\n",
      "dunzhang/stella_en_400M_v5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1652' max='1652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1652/1652 1:07:08, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.903700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.896900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.771700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.632700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.623800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    }
   ],
   "source": [
    "# å®Ÿé¨“çµæœæ ¼ç´ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "create_dir(cfg.data.results_path)\n",
    "\n",
    "model = SentenceTransformer(cfg.model.model_name, trust_remote_code=True)\n",
    "\n",
    "loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "FP = False if torch.cuda.is_bf16_supported() else True\n",
    "BF = True if torch.cuda.is_bf16_supported() else False\n",
    "print(f\"{torch.cuda.is_bf16_supported()=}\")\n",
    "\n",
    "print(f\"{cfg.model.model_name}ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚\")\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=cfg.data.results_path,\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=cfg.model.epoch,\n",
    "    per_device_train_batch_size=cfg.model.batch_size,\n",
    "    gradient_accumulation_steps=128 // cfg.model.batch_size,\n",
    "    per_device_eval_batch_size=cfg.model.batch_size,\n",
    "    eval_accumulation_steps=128 // cfg.model.batch_size,\n",
    "    learning_rate=cfg.model.lr,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=FP,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=BF,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # no duplicate samples in a batch\n",
    "    # Optional tracking/debugging parameters:\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=0.1,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    # report_to=REPORT_TO,  # Will be used in W&B if `wandb` is installed\n",
    "    # run_name=EXP_NAME,\n",
    "    do_eval=False,\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"AllText\", \"MisconceptionName_with_SubjectNames\", \"PredictMisconceptionName_with_SubjectNames\"]\n",
    "    ),\n",
    "    # train_dataset=formatted_dataset,\n",
    "    loss=loss,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(cfg.data.results_path, create_model_card=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "\n",
      "model.safetensors:   0%|          | 0.00/4.20M [00:00<?, ?B/s]\n",
      "model.safetensors:   3%|â–         | 131k/4.20M [00:00<00:03, 1.03MB/s]\n",
      "model.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.54M/4.20M [00:00<00:00, 7.59MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.20M/4.20M [00:01<00:00, 3.33MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.74G/1.74G [01:00<00:00, 28.6MB/s]\n",
      "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:01<00:00, 30.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/marumarukun/stella_en_400M_v5_fine_tuned_boosting_1/commit/840d918fe6ad6a23661582de7c7881001f876bf2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder, Repository\n",
    "\n",
    "# Hugging Faceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š\n",
    "HfFolder.save_token(\"your_huggingface_token\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã‚’Hugging Faceã«push\n",
    "model.push_to_hub(\n",
    "    \"marumarukun/stella_en_400M_v5_fine_tuned_boosting_1\",\n",
    "    commit_message=\"Add new SentenceTransformer model\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
