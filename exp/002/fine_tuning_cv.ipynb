{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '002'\n",
      "run_time: base\n",
      "data:\n",
      "  input_root: ../../data/input\n",
      "  train_path: ../../data/input/train.csv\n",
      "  test_path: ../../data/input/test.csv\n",
      "  sample_submission_path: ../../data/input/sample_submission.csv\n",
      "  mapping_path: ../../data/input/misconception_mapping.csv\n",
      "  mapping_meta_path: ../../data/input/mapping_meta.parquet\n",
      "  output_root: ../../data/output\n",
      "  results_root: ../../results\n",
      "  results_path: ../../results/002/base\n",
      "seed: 42\n",
      "k: 25\n",
      "n_splits: 4\n",
      "model:\n",
      "  model_name: BAAI/bge-large-en-v1.5\n",
      "  epoch: 2\n",
      "  lr: 2.0e-05\n",
      "  batch_size: 8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pytz\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from omegaconf import OmegaConf\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from transformers.trainer_utils import get_last_checkpoint  # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ‘ã‚¹ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "\n",
    "from src.config import cfg\n",
    "from src.data import add_subject_name_info, preprocess_train\n",
    "from src.dir import create_dir\n",
    "from src.metric import mapk, recall_at_k\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_bf16_supported()=True\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "FP = False if torch.cuda.is_bf16_supported() else True\n",
    "BF = True if torch.cuda.is_bf16_supported() else False\n",
    "print(f\"{torch.cuda.is_bf16_supported()=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "mapping = pl.read_csv(cfg.data.mapping_path, try_parse_dates=True)\n",
    "\n",
    "# CV\n",
    "gkf = StratifiedGroupKFold(n_splits=cfg.n_splits, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations to carry out calculations involving powers&quot;</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ?&quot;</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order of operations to carry out calculations involving powers SubjectName: BIDMAS QuestionText: \\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ? AnswerText: Does not need brackets&quot;</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( t \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( t \\)&quot;</td><td>&quot;A&quot;</td><td>&quot;1000_A&quot;</td><td>891</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerCText&quot;</td><td>&quot;\\( 1 \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( 1 \\)&quot;</td><td>&quot;C&quot;</td><td>&quot;1000_C&quot;</td><td>891</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 11)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ QuestionI â”† Construct â”† SubjectNa â”† QuestionT â”† â€¦ â”† AllText   â”† AnswerAlp â”† QuestionI â”† Misconce â”‚\n",
       "â”‚ d         â”† Name      â”† me        â”† ext       â”†   â”† ---       â”† habet     â”† d_Answer  â”† ptionId  â”‚\n",
       "â”‚ ---       â”† ---       â”† ---       â”† ---       â”†   â”† str       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ i64       â”† str       â”† str       â”† str       â”†   â”†           â”† str       â”† str       â”† i64      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0         â”† Use the   â”† BIDMAS    â”† \\[        â”† â€¦ â”† Construct â”† D         â”† 0_D       â”† 1672     â”‚\n",
       "â”‚           â”† order of  â”†           â”† 3 \\times  â”†   â”† Name: Use â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† operation â”†           â”† 2+4-5     â”†   â”† the order â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† s to      â”†           â”† \\]        â”†   â”† of operat â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† carry out â”†           â”† Where do  â”†   â”† ions to   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† calculati â”†           â”† the       â”†   â”† carry out â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ons       â”†           â”† brackets  â”†   â”† calculati â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† involving â”†           â”† need to   â”†   â”† ons       â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† powers    â”†           â”† go to     â”†   â”† involving â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† make the  â”†   â”† powers    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† answer    â”†   â”† SubjectNa â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† equal \\(  â”†   â”† me:       â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† 13 \\) ?   â”†   â”† BIDMAS    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† QuestionT â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ext: \\[   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 3 \\times  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 2+4-5     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\]        â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Where do  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† the       â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† brackets  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† need to   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† go to     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† make the  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† answer    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† equal \\(  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 13 \\) ?   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† AnswerTex â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† t: Does   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† not need  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† brackets  â”†           â”†           â”†          â”‚\n",
       "â”‚ 1000      â”† Simplify  â”† Simplifyi â”† Simplify  â”† â€¦ â”† Construct â”† A         â”† 1000_A    â”† 891      â”‚\n",
       "â”‚           â”† an        â”† ng        â”† the follo â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† algebraic â”† Algebraic â”† wing, if  â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fraction  â”† Fractions â”† possible: â”†   â”† an        â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† by factor â”†           â”† \\( \\frac{ â”†   â”† algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ising the â”†           â”† 1-t}{t-1} â”†   â”† fraction  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† numerator â”†           â”† \\)        â”†   â”† by factor â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ising the â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† numerator â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† SubjectNa â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† me: Simpl â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ifying    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Fractions â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† QuestionT â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ext:      â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† the follo â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† wing, if  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† possible: â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\( \\frac{ â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 1-t}{t-1} â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\) Answer â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Text: \\(  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† t \\)      â”†           â”†           â”†          â”‚\n",
       "â”‚ 1000      â”† Simplify  â”† Simplifyi â”† Simplify  â”† â€¦ â”† Construct â”† C         â”† 1000_C    â”† 891      â”‚\n",
       "â”‚           â”† an        â”† ng        â”† the follo â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† algebraic â”† Algebraic â”† wing, if  â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fraction  â”† Fractions â”† possible: â”†   â”† an        â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† by factor â”†           â”† \\( \\frac{ â”†   â”† algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ising the â”†           â”† 1-t}{t-1} â”†   â”† fraction  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† numerator â”†           â”† \\)        â”†   â”† by factor â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ising the â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† numerator â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† SubjectNa â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† me: Simpl â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ifying    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Fractions â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† QuestionT â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ext:      â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† the follo â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† wing, if  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† possible: â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\( \\frac{ â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 1-t}{t-1} â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\) Answer â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Text: \\(  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 1 \\)      â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainã®å‰å‡¦ç†\n",
    "train_long = preprocess_train(train)\n",
    "train_long.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹è¨˜ã®å‡¦ç†ã¯ãªã—ã§ã„ã„ã‹ã‚‚\n",
    "\n",
    "# # mappingã«SubjectNameã®æƒ…å ±ã‚’è¿½åŠ \n",
    "# mapping = add_subject_name_info(train, mapping)\n",
    "\n",
    "# mapping.head()\n",
    "\n",
    "# # NOTE: submitæ™‚ã¯ä¸‹è¨˜ã®ã‚ˆã†ã«testã®æƒ…å ±ã‚‚ä½¿ã† â†’ ã“ã‚Œã§CVã«ã‚ˆã‚‹å­¦ç¿’æ™‚ã¨åŒã˜æ¡ä»¶ã«ãªã‚‹\n",
    "# # train_test = pl.concat([train, test], how=\"diagonal\")\n",
    "# # mapping = add_subject_name_info(train_test, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retrieval_data(train_long, mapping, model, k):\n",
    "    # å•é¡Œæ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    train_long_vec = model.encode(train_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "\n",
    "    # èª¤æ¦‚å¿µã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "    # misconception_mapping_vec = model.encode(\n",
    "    #     mapping[\"MisconceptionName_with_SubjectNames\"].to_list(), normalize_embeddings=True\n",
    "    # )\n",
    "\n",
    "    # å•é¡Œæ–‡ã¨èª¤æ¦‚å¿µã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—\n",
    "    train_cos_sim_arr = cosine_similarity(train_long_vec, misconception_mapping_vec)\n",
    "    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ\n",
    "    train_sorted_indices = np.argsort(-train_cos_sim_arr, axis=1)\n",
    "\n",
    "    # å„å•é¡Œã«å¯¾ã—ã¦kå€‹ã®äºˆæ¸¬èª¤æ¦‚å¿µIDã‚’è¿½åŠ \n",
    "    train_long = train_long.with_columns(\n",
    "        pl.Series(train_sorted_indices[:, :k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    # äºˆæ¸¬èª¤æ¦‚å¿µã®æƒ…å ±ã‚’çµåˆ\n",
    "    train_retrieved = (\n",
    "        # äºˆæ¸¬èª¤æ¦‚å¿µIDãƒªã‚¹ãƒˆã‚’å±•é–‹\n",
    "        train_long.explode(\"PredictMisconceptionId\")\n",
    "        # æ­£è§£ã®èª¤æ¦‚å¿µæƒ…å ±ã‚’çµåˆ\n",
    "        .join(mapping, on=\"MisconceptionId\")\n",
    "        # äºˆæ¸¬ã®èª¤æ¦‚å¿µæƒ…å ±ã‚’çµåˆ(ã‚«ãƒ©ãƒ åã«\"Predict\"ã‚’ä»˜ä¸)\n",
    "        .join(mapping.rename(lambda x: \"Predict\" + x), on=\"PredictMisconceptionId\")\n",
    "        # æ­£è§£ã¨äºˆæ¸¬ãŒä¸€è‡´ã™ã‚‹è¡Œã‚’å‰Šé™¤\n",
    "        .filter(pl.col(\"MisconceptionId\") != pl.col(\"PredictMisconceptionId\"))\n",
    "    )\n",
    "\n",
    "    return train_retrieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:994: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ../../results/002/20241115_191836/fold1\n",
      "BAAI/bge-large-en-v1.5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚(1/4fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1246' max='1246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1246/1246 1:09:32, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.591400</td>\n",
       "      <td>1.645703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.419000</td>\n",
       "      <td>1.436509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.447600</td>\n",
       "      <td>1.416140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.293400</td>\n",
       "      <td>1.314739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.260200</td>\n",
       "      <td>1.224498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.036100</td>\n",
       "      <td>1.280077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.821700</td>\n",
       "      <td>1.191153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.810500</td>\n",
       "      <td>1.143917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.742600</td>\n",
       "      <td>1.127625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ fold1 result================\n",
      "\n",
      "map@25: 0.3591846734674502\n",
      "recall@25: 0.8057813911472448\n",
      "Directory created: ../../results/002/20241115_191836/fold2\n",
      "BAAI/bge-large-en-v1.5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚(2/4fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1256' max='1256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1256/1256 1:10:18, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.687800</td>\n",
       "      <td>1.664911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>1.383900</td>\n",
       "      <td>1.603054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>1.447800</td>\n",
       "      <td>1.465591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>1.259400</td>\n",
       "      <td>1.383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.204500</td>\n",
       "      <td>1.339231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>1.125600</td>\n",
       "      <td>1.279923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>0.770700</td>\n",
       "      <td>1.258460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>0.719300</td>\n",
       "      <td>1.248567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0.731800</td>\n",
       "      <td>1.218055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ fold2 result================\n",
      "\n",
      "map@25: 0.33887390478973967\n",
      "recall@25: 0.7511520737327189\n",
      "Directory created: ../../results/002/20241115_191836/fold3\n",
      "BAAI/bge-large-en-v1.5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚(3/4fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1256' max='1256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1256/1256 1:09:53, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.672600</td>\n",
       "      <td>1.707100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>1.408100</td>\n",
       "      <td>1.405868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>1.431500</td>\n",
       "      <td>1.436536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>1.290100</td>\n",
       "      <td>1.281688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.212700</td>\n",
       "      <td>1.230119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>1.178300</td>\n",
       "      <td>1.216008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>1.234019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>0.749900</td>\n",
       "      <td>1.191216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0.763600</td>\n",
       "      <td>1.166200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ fold3 result================\n",
      "\n",
      "map@25: 0.3425523545993542\n",
      "recall@25: 0.7604070305272895\n",
      "Directory created: ../../results/002/20241115_191836/fold4\n",
      "BAAI/bge-large-en-v1.5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚(4/4fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1252 : < :, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 22.15 GiB of which 16.00 MiB is free. Process 3759331 has 22.13 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, and 21.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 69\u001b[0m\n\u001b[1;32m     27\u001b[0m args \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainingArguments(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Required parameter:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39msave_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     do_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m     59\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     60\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m     67\u001b[0m )\n\u001b[0;32m---> 69\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(save_dir, create_model_card\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# è©•ä¾¡\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/trainer.py:344\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    338\u001b[0m     model \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel  \u001b[38;5;66;03m# Only if the model is wrapped\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(loss_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Only if the loss stores the model\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m loss_fn\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m model  \u001b[38;5;66;03m# Only if the wrapped model is not already stored\u001b[39;00m\n\u001b[1;32m    342\u001b[0m ):\n\u001b[1;32m    343\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_model_in_loss(loss_fn, model)\n\u001b[0;32m--> 344\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_outputs:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# During prediction/evaluation, `compute_loss` will be called with `return_outputs=True`.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;66;03m# However, Sentence Transformer losses do not return outputs, so we return an empty dictionary.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# This does not result in any problems, as the SentenceTransformerTrainingArguments sets\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# `prediction_loss_only=True` which means that the output is not used.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, {}\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py:99\u001b[0m, in \u001b[0;36mMultipleNegativesRankingLoss.forward\u001b[0;34m(self, sentence_features, labels)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 99\u001b[0m     reps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sentence_feature \u001b[38;5;129;01min\u001b[39;00m sentence_features]\n\u001b[1;32m    100\u001b[0m     embeddings_a \u001b[38;5;241m=\u001b[39m reps[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m     embeddings_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(reps[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:823\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:811\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:668\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    667\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:640\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    554\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 22.15 GiB of which 16.00 MiB is free. Process 3759331 has 22.13 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, and 21.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# å®Ÿé¨“çµæœæ ¼ç´ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "map_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(\n",
    "    gkf.split(train_long, groups=train_long[\"QuestionId\"], y=train_long[\"SubjectName\"])\n",
    "):\n",
    "    save_dir = os.path.join(cfg.data.results_path, f\"fold{i+1}\")\n",
    "    create_dir(save_dir)\n",
    "\n",
    "    model = SentenceTransformer(cfg.model.model_name)\n",
    "\n",
    "    train_retrieved = make_retrieval_data(train_long[train_idx], mapping, model, cfg.k)\n",
    "    valid_retrieved = make_retrieval_data(train_long[valid_idx], mapping, model, cfg.k)\n",
    "    train_dataset = Dataset.from_polars(train_retrieved)\n",
    "    valid_dataset = Dataset.from_polars(valid_retrieved)\n",
    "    if DEBUG:\n",
    "        train_dataset = train_dataset.select(range(50))\n",
    "        valid_dataset = valid_dataset.select(range(50))\n",
    "    loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "    print(f\"{cfg.model.model_name}ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚({i+1}/{gkf.n_splits}fold)\")\n",
    "\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        output_dir=save_dir,\n",
    "        # Optional training parameters:\n",
    "        num_train_epochs=cfg.model.epoch,\n",
    "        per_device_train_batch_size=cfg.model.batch_size,\n",
    "        gradient_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        per_device_eval_batch_size=cfg.model.batch_size,\n",
    "        eval_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        learning_rate=cfg.model.lr,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=FP,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "        bf16=BF,  # Set to True if you have a GPU that supports BF16\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # no duplicate samples in a batch\n",
    "        # Optional tracking/debugging parameters:\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=0.1,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.1,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"loss\",\n",
    "        greater_is_better=False,\n",
    "        logging_steps=100,\n",
    "        # report_to=REPORT_TO,  # Will be used in W&B if `wandb` is installed\n",
    "        # run_name=EXP_NAME,\n",
    "        do_eval=True,\n",
    "    )\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset.select_columns([\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]),\n",
    "        # train_dataset=train_dataset.select_columns(\n",
    "        #     [\"AllText\", \"MisconceptionName_with_SubjectNames\", \"PredictMisconceptionName_with_SubjectNames\"]\n",
    "        # ),\n",
    "        eval_dataset=valid_dataset.select_columns([\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]),\n",
    "        loss=loss,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(save_dir, create_model_card=False)\n",
    "\n",
    "    # è©•ä¾¡\n",
    "\n",
    "    valid_long = train_long[valid_idx]\n",
    "    # å•é¡Œæ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    valid_long_vec = model.encode(valid_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "    # èª¤æ¦‚å¿µã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "    # å•é¡Œæ–‡ã¨èª¤æ¦‚å¿µã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—\n",
    "    valid_cos_sim_arr = cosine_similarity(valid_long_vec, misconception_mapping_vec)\n",
    "    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ\n",
    "    valid_sorted_indices = np.argsort(-valid_cos_sim_arr, axis=1)\n",
    "    # å„å•é¡Œã«å¯¾ã—ã¦kå€‹ã®äºˆæ¸¬èª¤æ¦‚å¿µIDã‚’è¿½åŠ \n",
    "    valid_long = valid_long.with_columns(\n",
    "        pl.Series(valid_sorted_indices[:, : cfg.k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    actual_misconception_ids = [[mis_id] for mis_id in valid_long[\"MisconceptionId\"].to_list()]\n",
    "    predicted_misconception_ids = valid_long[\"PredictMisconceptionId\"].to_list()\n",
    "    # map@25\n",
    "    map_score = mapk(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    # recall@25\n",
    "    recall_score = recall_at_k(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    recall_scores.append(recall_score)\n",
    "\n",
    "    print(f\"\\n================ fold{i+1} result================\\n\")\n",
    "    print(f\"map@25: {map_score}\")\n",
    "    print(f\"recall@25: {recall_score}\")\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "print(\"\\n================CV result================\\n\")\n",
    "print(f\"map@25: {np.mean(map_scores)}\")\n",
    "print(f\"recall@25: {np.mean(recall_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceã«push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [04:01<00:00, 5.56MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:41<00:00, 32.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:41<00:00, 32.0MB/s]\n",
      "No sentence-transformers model found with name ../../results/002/20241115_191836/fold4. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model in ../../results/002/20241115_191836/fold4. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zoedepth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mresults_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model_name \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:306\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[1;32m    294\u001b[0m         modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(\n\u001b[1;32m    295\u001b[0m             model_name_or_path,\n\u001b[1;32m    296\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m             config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m         modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_auto_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modules, OrderedDict):\n\u001b[1;32m    319\u001b[0m     modules \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1454\u001b[0m, in \u001b[0;36mSentenceTransformer._load_auto_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m tokenizer_kwargs \u001b[38;5;241m=\u001b[39m shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m tokenizer_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mshared_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs}\n\u001b[1;32m   1452\u001b[0m config_kwargs \u001b[38;5;241m=\u001b[39m shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m config_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mshared_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs}\n\u001b[0;32m-> 1454\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1461\u001b[0m pooling_model \u001b[38;5;241m=\u001b[39m Pooling(transformer_model\u001b[38;5;241m.\u001b[39mget_word_embedding_dimension(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_card_data\u001b[38;5;241m.\u001b[39mset_base_model(model_name_or_path, revision\u001b[38;5;241m=\u001b[39mrevision)\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:55\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 55\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n",
      "File \u001b[0;32m~/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1038\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[1;32m   1036\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern]\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized model in ../../results/002/20241115_191836/fold4. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zoedepth"
     ]
    }
   ],
   "source": [
    "# huggingfaceã«push\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# Hugging Faceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š\n",
    "HfFolder.save_token(\"your_huggingface_token\")\n",
    "\n",
    "# å„foldã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒƒã‚·ãƒ¥\n",
    "for i in range(cfg.n_splits):\n",
    "    fold = i + 1\n",
    "    save_dir = os.path.join(cfg.data.results_path, f\"fold{fold}\")\n",
    "\n",
    "    # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
    "    model = SentenceTransformer(save_dir)\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤\n",
    "    model_name = cfg.model.model_name.replace(\"/\", \"-\")\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’Hugging Faceã«push\n",
    "    model.push_to_hub(\n",
    "        f\"marumarukun/{model_name}_fine_tuned_fold{fold}_{cfg.run_time}\",\n",
    "        commit_message=f\"Add fold{fold} SentenceTransformer model\",\n",
    "    )\n",
    "    print(f\"Fold {fold} ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
