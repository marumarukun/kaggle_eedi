{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '002'\n",
      "run_time: base\n",
      "data:\n",
      "  input_root: ../../data/input\n",
      "  train_path: ../../data/input/train.csv\n",
      "  test_path: ../../data/input/test.csv\n",
      "  sample_submission_path: ../../data/input/sample_submission.csv\n",
      "  mapping_path: ../../data/input/misconception_mapping.csv\n",
      "  mapping_meta_path: ../../data/input/mapping_meta.parquet\n",
      "  output_root: ../../data/output\n",
      "  results_root: ../../results\n",
      "  results_path: ../../results/002/base\n",
      "seed: 42\n",
      "k: 25\n",
      "model:\n",
      "  model_name: BAAI/bge-large-en-v1.5\n",
      "  epoch: 2\n",
      "  lr: 2.0e-05\n",
      "  batch_size: 8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pytz\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from omegaconf import OmegaConf\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from src.config import cfg\n",
    "from src.data import add_subject_name_info, preprocess_train\n",
    "from src.dir import create_dir\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_bf16_supported()=True\n"
     ]
    }
   ],
   "source": [
    "DEBUG = True\n",
    "FP = False if torch.cuda.is_bf16_supported() else True\n",
    "BF = True if torch.cuda.is_bf16_supported() else False\n",
    "print(f\"{torch.cuda.is_bf16_supported()=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
    "\n",
    "\n",
    "def recall_at_k(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the recall at k for predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements to evaluate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "            The mean recall@k over the input lists\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for act, pred in zip(actual, predicted):\n",
    "        pred_at_k = pred[:k]\n",
    "        num_correct = len(set(act) & set(pred_at_k))\n",
    "        recall = num_correct / len(act) if len(act) > 0 else 0.0\n",
    "        scores.append(recall)\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "mapping = pl.read_csv(cfg.data.mapping_path, try_parse_dates=True)\n",
    "\n",
    "# CV\n",
    "gkf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations to carry out calculations involving powers&quot;</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ?&quot;</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order of operations to carry out calculations involving powers SubjectName: BIDMAS QuestionText: \\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ? AnswerText: Does not need brackets&quot;</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( t \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( t \\)&quot;</td><td>&quot;A&quot;</td><td>&quot;1000_A&quot;</td><td>891</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerCText&quot;</td><td>&quot;\\( 1 \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( 1 \\)&quot;</td><td>&quot;C&quot;</td><td>&quot;1000_C&quot;</td><td>891</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 11)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ QuestionI ┆ Construct ┆ SubjectNa ┆ QuestionT ┆ … ┆ AllText   ┆ AnswerAlp ┆ QuestionI ┆ Misconce │\n",
       "│ d         ┆ Name      ┆ me        ┆ ext       ┆   ┆ ---       ┆ habet     ┆ d_Answer  ┆ ptionId  │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ str       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i64       ┆ str       ┆ str       ┆ str       ┆   ┆           ┆ str       ┆ str       ┆ i64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0         ┆ Use the   ┆ BIDMAS    ┆ \\[        ┆ … ┆ Construct ┆ D         ┆ 0_D       ┆ 1672     │\n",
       "│           ┆ order of  ┆           ┆ 3 \\times  ┆   ┆ Name: Use ┆           ┆           ┆          │\n",
       "│           ┆ operation ┆           ┆ 2+4-5     ┆   ┆ the order ┆           ┆           ┆          │\n",
       "│           ┆ s to      ┆           ┆ \\]        ┆   ┆ of operat ┆           ┆           ┆          │\n",
       "│           ┆ carry out ┆           ┆ Where do  ┆   ┆ ions to   ┆           ┆           ┆          │\n",
       "│           ┆ calculati ┆           ┆ the       ┆   ┆ carry out ┆           ┆           ┆          │\n",
       "│           ┆ ons       ┆           ┆ brackets  ┆   ┆ calculati ┆           ┆           ┆          │\n",
       "│           ┆ involving ┆           ┆ need to   ┆   ┆ ons       ┆           ┆           ┆          │\n",
       "│           ┆ powers    ┆           ┆ go to     ┆   ┆ involving ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ make the  ┆   ┆ powers    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ answer    ┆   ┆ SubjectNa ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ equal \\(  ┆   ┆ me:       ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 13 \\) ?   ┆   ┆ BIDMAS    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ QuestionT ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ext: \\[   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 3 \\times  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2+4-5     ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\]        ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Where do  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the       ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ brackets  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ need to   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ go to     ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ make the  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ answer    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ equal \\(  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 13 \\) ?   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ AnswerTex ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ t: Does   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ not need  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ brackets  ┆           ┆           ┆          │\n",
       "│ 1000      ┆ Simplify  ┆ Simplifyi ┆ Simplify  ┆ … ┆ Construct ┆ A         ┆ 1000_A    ┆ 891      │\n",
       "│           ┆ an        ┆ ng        ┆ the follo ┆   ┆ Name:     ┆           ┆           ┆          │\n",
       "│           ┆ algebraic ┆ Algebraic ┆ wing, if  ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆ fraction  ┆ Fractions ┆ possible: ┆   ┆ an        ┆           ┆           ┆          │\n",
       "│           ┆ by factor ┆           ┆ \\( \\frac{ ┆   ┆ algebraic ┆           ┆           ┆          │\n",
       "│           ┆ ising the ┆           ┆ 1-t}{t-1} ┆   ┆ fraction  ┆           ┆           ┆          │\n",
       "│           ┆ numerator ┆           ┆ \\)        ┆   ┆ by factor ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ising the ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ numerator ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ SubjectNa ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ me: Simpl ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ifying    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Algebraic ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Fractions ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ QuestionT ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ext:      ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the follo ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ wing, if  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ possible: ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\( \\frac{ ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1-t}{t-1} ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\) Answer ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Text: \\(  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ t \\)      ┆           ┆           ┆          │\n",
       "│ 1000      ┆ Simplify  ┆ Simplifyi ┆ Simplify  ┆ … ┆ Construct ┆ C         ┆ 1000_C    ┆ 891      │\n",
       "│           ┆ an        ┆ ng        ┆ the follo ┆   ┆ Name:     ┆           ┆           ┆          │\n",
       "│           ┆ algebraic ┆ Algebraic ┆ wing, if  ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆ fraction  ┆ Fractions ┆ possible: ┆   ┆ an        ┆           ┆           ┆          │\n",
       "│           ┆ by factor ┆           ┆ \\( \\frac{ ┆   ┆ algebraic ┆           ┆           ┆          │\n",
       "│           ┆ ising the ┆           ┆ 1-t}{t-1} ┆   ┆ fraction  ┆           ┆           ┆          │\n",
       "│           ┆ numerator ┆           ┆ \\)        ┆   ┆ by factor ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ising the ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ numerator ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ SubjectNa ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ me: Simpl ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ifying    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Algebraic ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Fractions ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ QuestionT ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ext:      ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the follo ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ wing, if  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ possible: ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\( \\frac{ ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1-t}{t-1} ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\) Answer ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Text: \\(  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1 \\)      ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainの前処理\n",
    "train_long = preprocess_train(train)\n",
    "train_long.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>MisconceptionId</th><th>MisconceptionName</th><th>SubjectNames</th><th>MisconceptionName_with_SubjectNames</th></tr><tr><td>i64</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Does not know that angles in a triangle sum to 180 degrees&quot;</td><td>[&quot;Angles in Triangles&quot;]</td><td>&quot;The misconception &#x27;Does not know that angles in a triangle sum to 180 degrees&#x27; is primarily observed in the following subjects: Angles in Triangles&quot;</td></tr><tr><td>1</td><td>&quot;Uses dividing fractions method for multiplying fractions&quot;</td><td>[&quot;Multiplying and Dividing Negative Numbers&quot;, &quot;Multiplying Fractions&quot;]</td><td>&quot;The misconception &#x27;Uses dividing fractions method for multiplying fractions&#x27; is primarily observed in the following subjects: Multiplying and Dividing Negative Numbers, Multiplying Fractions&quot;</td></tr><tr><td>2</td><td>&quot;Believes there are 100 degrees in a full turn&quot;</td><td>[&quot;Types, Naming and Estimating&quot;, &quot;Measuring Angles&quot;]</td><td>&quot;The misconception &#x27;Believes there are 100 degrees in a full turn&#x27; is primarily observed in the following subjects: Types, Naming and Estimating, Measuring Angles&quot;</td></tr><tr><td>3</td><td>&quot;Thinks a quadratic without a non variable term, can not be factorised&quot;</td><td>[&quot;Factorising into a Single Bracket&quot;]</td><td>&quot;The misconception &#x27;Thinks a quadratic without a non variable term, can not be factorised&#x27; is primarily observed in the following subjects: Factorising into a Single Bracket&quot;</td></tr><tr><td>4</td><td>&quot;Believes addition of terms and powers of terms are equivalent e.g. a + c = a^c&quot;</td><td>[&quot;Simplifying Expressions by Collecting Like Terms&quot;]</td><td>&quot;The misconception &#x27;Believes addition of terms and powers of terms are equivalent e.g. a + c = a^c&#x27; is primarily observed in the following subjects: Simplifying Expressions by Collecting Like Terms&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────┬──────────────────────────┬──────────────────────────┬──────────────────────────┐\n",
       "│ MisconceptionId ┆ MisconceptionName        ┆ SubjectNames             ┆ MisconceptionName_with_S │\n",
       "│ ---             ┆ ---                      ┆ ---                      ┆ ubjectNames              │\n",
       "│ i64             ┆ str                      ┆ list[str]                ┆ ---                      │\n",
       "│                 ┆                          ┆                          ┆ str                      │\n",
       "╞═════════════════╪══════════════════════════╪══════════════════════════╪══════════════════════════╡\n",
       "│ 0               ┆ Does not know that       ┆ [\"Angles in Triangles\"]  ┆ The misconception 'Does  │\n",
       "│                 ┆ angles in a triangle sum ┆                          ┆ not know that angles in  │\n",
       "│                 ┆ to 180 degrees           ┆                          ┆ a triangle sum to 180    │\n",
       "│                 ┆                          ┆                          ┆ degrees' is primarily    │\n",
       "│                 ┆                          ┆                          ┆ observed in the          │\n",
       "│                 ┆                          ┆                          ┆ following subjects:      │\n",
       "│                 ┆                          ┆                          ┆ Angles in Triangles      │\n",
       "│ 1               ┆ Uses dividing fractions  ┆ [\"Multiplying and        ┆ The misconception 'Uses  │\n",
       "│                 ┆ method for multiplying   ┆ Dividing Negative        ┆ dividing fractions       │\n",
       "│                 ┆ fractions                ┆ Numbers\", \"Multiplying   ┆ method for multiplying   │\n",
       "│                 ┆                          ┆ Fractions\"]              ┆ fractions' is primarily  │\n",
       "│                 ┆                          ┆                          ┆ observed in the          │\n",
       "│                 ┆                          ┆                          ┆ following subjects:      │\n",
       "│                 ┆                          ┆                          ┆ Multiplying and Dividing │\n",
       "│                 ┆                          ┆                          ┆ Negative Numbers,        │\n",
       "│                 ┆                          ┆                          ┆ Multiplying Fractions    │\n",
       "│ 2               ┆ Believes there are 100   ┆ [\"Types, Naming and      ┆ The misconception        │\n",
       "│                 ┆ degrees in a full turn   ┆ Estimating\", \"Measuring  ┆ 'Believes there are 100  │\n",
       "│                 ┆                          ┆ Angles\"]                 ┆ degrees in a full turn'  │\n",
       "│                 ┆                          ┆                          ┆ is primarily observed in │\n",
       "│                 ┆                          ┆                          ┆ the following subjects:  │\n",
       "│                 ┆                          ┆                          ┆ Types, Naming and        │\n",
       "│                 ┆                          ┆                          ┆ Estimating, Measuring    │\n",
       "│                 ┆                          ┆                          ┆ Angles                   │\n",
       "│ 3               ┆ Thinks a quadratic       ┆ [\"Factorising into a     ┆ The misconception        │\n",
       "│                 ┆ without a non variable   ┆ Single Bracket\"]         ┆ 'Thinks a quadratic      │\n",
       "│                 ┆ term, can not be         ┆                          ┆ without a non variable   │\n",
       "│                 ┆ factorised               ┆                          ┆ term, can not be         │\n",
       "│                 ┆                          ┆                          ┆ factorised' is primarily │\n",
       "│                 ┆                          ┆                          ┆ observed in the          │\n",
       "│                 ┆                          ┆                          ┆ following subjects:      │\n",
       "│                 ┆                          ┆                          ┆ Factorising into a       │\n",
       "│                 ┆                          ┆                          ┆ Single Bracket           │\n",
       "│ 4               ┆ Believes addition of     ┆ [\"Simplifying            ┆ The misconception        │\n",
       "│                 ┆ terms and powers of      ┆ Expressions by           ┆ 'Believes addition of    │\n",
       "│                 ┆ terms are equivalent     ┆ Collecting Like Terms\"]  ┆ terms and powers of      │\n",
       "│                 ┆ e.g. a + c = a^c         ┆                          ┆ terms are equivalent     │\n",
       "│                 ┆                          ┆                          ┆ e.g. a + c = a^c' is     │\n",
       "│                 ┆                          ┆                          ┆ primarily observed in    │\n",
       "│                 ┆                          ┆                          ┆ the following subjects:  │\n",
       "│                 ┆                          ┆                          ┆ Simplifying Expressions  │\n",
       "│                 ┆                          ┆                          ┆ by Collecting Like Terms │\n",
       "└─────────────────┴──────────────────────────┴──────────────────────────┴──────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下記の処理はなしでいいかも\n",
    "\n",
    "# # mappingにSubjectNameの情報を追加\n",
    "# mapping = add_subject_name_info(train, mapping)\n",
    "\n",
    "# mapping.head()\n",
    "\n",
    "# # NOTE: submit時は下記のようにtestの情報も使う → これでCVによる学習時と同じ条件になる\n",
    "# # train_test = pl.concat([train, test], how=\"diagonal\")\n",
    "# # mapping = add_subject_name_info(train_test, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retrieval_data(train_long, mapping, model, k):\n",
    "    # 問題文をベクトル化\n",
    "    train_long_vec = model.encode(train_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "\n",
    "    # 誤概念をベクトル化\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "    # misconception_mapping_vec = model.encode(\n",
    "    #     mapping[\"MisconceptionName_with_SubjectNames\"].to_list(), normalize_embeddings=True\n",
    "    # )\n",
    "\n",
    "    # 問題文と誤概念のコサイン類似度を計算\n",
    "    train_cos_sim_arr = cosine_similarity(train_long_vec, misconception_mapping_vec)\n",
    "    # コサイン類似度が高い順にソート\n",
    "    train_sorted_indices = np.argsort(-train_cos_sim_arr, axis=1)\n",
    "\n",
    "    # 各問題に対してk個の予測誤概念IDを追加\n",
    "    train_long = train_long.with_columns(\n",
    "        pl.Series(train_sorted_indices[:, :k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    # 予測誤概念の情報を結合\n",
    "    train_retrieved = (\n",
    "        # 予測誤概念IDリストを展開\n",
    "        train_long.explode(\"PredictMisconceptionId\")\n",
    "        # 正解の誤概念情報を結合\n",
    "        .join(mapping, on=\"MisconceptionId\")\n",
    "        # 予測の誤概念情報を結合(カラム名に\"Predict\"を付与)\n",
    "        .join(mapping.rename(lambda x: \"Predict\" + x), on=\"PredictMisconceptionId\")\n",
    "        # 正解と予測が一致する行を削除\n",
    "        .filter(pl.col(\"MisconceptionId\") != pl.col(\"PredictMisconceptionId\"))\n",
    "    )\n",
    "\n",
    "    return train_retrieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:994: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ../../results/002/20241114_170703/fold1\n",
      "BAAI/bge-large-en-v1.5のfine-tuningを開始します。(1/4fold)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1236' max='1236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1236/1236 3:36:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.970300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.990300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.933300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.871800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.745200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.663100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ fold1 result================\n",
      "\n",
      "map@25: 0.22494125733353018\n",
      "recall@25: 0.5889792231255646\n",
      "Directory created: ../../results/002/20241114_170703/fold2\n",
      "BAAI/bge-large-en-v1.5のfine-tuningを開始します。(2/4fold)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='1244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 960/1244 13:23:20 < 3:58:09, 0.02 it/s, Epoch 1.54/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.214800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.803300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    }
   ],
   "source": [
    "# 実験結果格納用のディレクトリを作成\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "map_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(\n",
    "    gkf.split(train_long, groups=train_long[\"QuestionId\"], y=train_long[\"SubjectName\"])\n",
    "):\n",
    "    save_dir = os.path.join(cfg.data.results_path, f\"fold{i+1}\")\n",
    "    create_dir(save_dir)\n",
    "\n",
    "    model = SentenceTransformer(cfg.model.model_name)\n",
    "\n",
    "    train_retrieved = make_retrieval_data(train_long[train_idx], mapping, model, cfg.k)\n",
    "    train_dataset = Dataset.from_polars(train_retrieved)\n",
    "    if DEBUG:\n",
    "        train_dataset = train_dataset.select(range(50))\n",
    "\n",
    "    loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "    print(f\"{cfg.model.model_name}のfine-tuningを開始します。({i+1}/{gkf.n_splits}fold)\")\n",
    "\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        output_dir=save_dir,\n",
    "        # Optional training parameters:\n",
    "        num_train_epochs=cfg.model.epoch,\n",
    "        per_device_train_batch_size=cfg.model.batch_size,\n",
    "        gradient_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        per_device_eval_batch_size=cfg.model.batch_size,\n",
    "        eval_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        learning_rate=cfg.model.lr,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=FP,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "        bf16=BF,  # Set to True if you have a GPU that supports BF16\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # no duplicate samples in a batch\n",
    "        # Optional tracking/debugging parameters:\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.1,\n",
    "        save_total_limit=1,\n",
    "        logging_steps=100,\n",
    "        # report_to=REPORT_TO,  # Will be used in W&B if `wandb` is installed\n",
    "        # run_name=EXP_NAME,\n",
    "        do_eval=False,\n",
    "    )\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset.select_columns([\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]),\n",
    "        # train_dataset=train_dataset.select_columns(\n",
    "        #     [\"AllText\", \"MisconceptionName_with_SubjectNames\", \"PredictMisconceptionName_with_SubjectNames\"]\n",
    "        # ),\n",
    "        loss=loss,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(save_dir, create_model_card=False)\n",
    "\n",
    "    # 評価\n",
    "\n",
    "    valid_long = train_long[valid_idx]\n",
    "    # 問題文をベクトル化\n",
    "    valid_long_vec = model.encode(valid_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "    # 誤概念をベクトル化\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "    # 問題文と誤概念のコサイン類似度を計算\n",
    "    valid_cos_sim_arr = cosine_similarity(valid_long_vec, misconception_mapping_vec)\n",
    "    # コサイン類似度が高い順にソート\n",
    "    valid_sorted_indices = np.argsort(-valid_cos_sim_arr, axis=1)\n",
    "    # 各問題に対してk個の予測誤概念IDを追加\n",
    "    valid_long = valid_long.with_columns(\n",
    "        pl.Series(valid_sorted_indices[:, : cfg.k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    actual_misconception_ids = [[mis_id] for mis_id in valid_long[\"MisconceptionId\"].to_list()]\n",
    "    predicted_misconception_ids = valid_long[\"PredictMisconceptionId\"].to_list()\n",
    "    # map@25\n",
    "    map_score = mapk(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    # recall@25\n",
    "    recall_score = recall_at_k(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    recall_scores.append(recall_score)\n",
    "\n",
    "    print(f\"\\n================ fold{i+1} result================\\n\")\n",
    "    print(f\"map@25: {np.mean(map_scores)}\")\n",
    "    print(f\"recall@25: {np.mean(recall_scores)}\")\n",
    "\n",
    "\n",
    "print(\"\\n================CV result================\\n\")\n",
    "print(f\"map@25: {np.mean(map_scores)}\")\n",
    "print(f\"recall@25: {np.mean(recall_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceにpush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/home/marumarukun/pj/compe/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "model.safetensors: 100%|██████████| 1.34G/1.34G [01:43<00:00, 12.9MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/marumarukun/bge_large_en_v1.5_fine_tuned_boosting_1/commit/18a99a5e6c672bbe1e38565c4fc5f40194dc3363'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# huggingfaceにpush\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# Hugging Faceのトークンを設定\n",
    "HfFolder.save_token(\"your_huggingface_token\")\n",
    "\n",
    "# モデルをHugging Faceにpush\n",
    "model.push_to_hub(\n",
    "    \"marumarukun/bge_large_en_v1.5_fine_tuned_boosting_1\",\n",
    "    commit_message=\"Add new SentenceTransformer model\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
