{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '002'\n",
      "run_time: base\n",
      "data:\n",
      "  input_root: ../../data/input\n",
      "  train_path: ../../data/input/train.csv\n",
      "  test_path: ../../data/input/test.csv\n",
      "  sample_submission_path: ../../data/input/sample_submission.csv\n",
      "  mapping_path: ../../data/input/misconception_mapping.csv\n",
      "  mapping_meta_path: ../../data/input/mapping_meta.parquet\n",
      "  output_root: ../../data/output\n",
      "  results_root: ../../results\n",
      "  results_path: ../../results/002/base\n",
      "seed: 42\n",
      "k: 25\n",
      "model:\n",
      "  model_name: BAAI/bge-large-en-v1.5\n",
      "  epoch: 2\n",
      "  lr: 2.0e-05\n",
      "  batch_size: 8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pytz\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from omegaconf import OmegaConf\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from transformers.trainer_utils import get_last_checkpoint  # 最新のチェックポイントのパスを取得する関数\n",
    "\n",
    "from src.config import cfg\n",
    "from src.data import add_subject_name_info, preprocess_train\n",
    "from src.dir import create_dir\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_bf16_supported()=True\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "FP = False if torch.cuda.is_bf16_supported() else True\n",
    "BF = True if torch.cuda.is_bf16_supported() else False\n",
    "print(f\"{torch.cuda.is_bf16_supported()=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
    "\n",
    "\n",
    "def recall_at_k(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the recall at k for predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements to evaluate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "            The mean recall@k over the input lists\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for act, pred in zip(actual, predicted):\n",
    "        pred_at_k = pred[:k]\n",
    "        num_correct = len(set(act) & set(pred_at_k))\n",
    "        recall = num_correct / len(act) if len(act) > 0 else 0.0\n",
    "        scores.append(recall)\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "mapping = pl.read_csv(cfg.data.mapping_path, try_parse_dates=True)\n",
    "\n",
    "# CV\n",
    "gkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations to carry out calculations involving powers&quot;</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ?&quot;</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order of operations to carry out calculations involving powers SubjectName: BIDMAS QuestionText: \\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ? AnswerText: Does not need brackets&quot;</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( t \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( t \\)&quot;</td><td>&quot;A&quot;</td><td>&quot;1000_A&quot;</td><td>891</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerCText&quot;</td><td>&quot;\\( 1 \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( 1 \\)&quot;</td><td>&quot;C&quot;</td><td>&quot;1000_C&quot;</td><td>891</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 11)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ QuestionI ┆ Construct ┆ SubjectNa ┆ QuestionT ┆ … ┆ AllText   ┆ AnswerAlp ┆ QuestionI ┆ Misconce │\n",
       "│ d         ┆ Name      ┆ me        ┆ ext       ┆   ┆ ---       ┆ habet     ┆ d_Answer  ┆ ptionId  │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ str       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i64       ┆ str       ┆ str       ┆ str       ┆   ┆           ┆ str       ┆ str       ┆ i64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0         ┆ Use the   ┆ BIDMAS    ┆ \\[        ┆ … ┆ Construct ┆ D         ┆ 0_D       ┆ 1672     │\n",
       "│           ┆ order of  ┆           ┆ 3 \\times  ┆   ┆ Name: Use ┆           ┆           ┆          │\n",
       "│           ┆ operation ┆           ┆ 2+4-5     ┆   ┆ the order ┆           ┆           ┆          │\n",
       "│           ┆ s to      ┆           ┆ \\]        ┆   ┆ of operat ┆           ┆           ┆          │\n",
       "│           ┆ carry out ┆           ┆ Where do  ┆   ┆ ions to   ┆           ┆           ┆          │\n",
       "│           ┆ calculati ┆           ┆ the       ┆   ┆ carry out ┆           ┆           ┆          │\n",
       "│           ┆ ons       ┆           ┆ brackets  ┆   ┆ calculati ┆           ┆           ┆          │\n",
       "│           ┆ involving ┆           ┆ need to   ┆   ┆ ons       ┆           ┆           ┆          │\n",
       "│           ┆ powers    ┆           ┆ go to     ┆   ┆ involving ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ make the  ┆   ┆ powers    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ answer    ┆   ┆ SubjectNa ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ equal \\(  ┆   ┆ me:       ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 13 \\) ?   ┆   ┆ BIDMAS    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ QuestionT ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ext: \\[   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 3 \\times  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2+4-5     ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\]        ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Where do  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the       ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ brackets  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ need to   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ go to     ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ make the  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ answer    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ equal \\(  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 13 \\) ?   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ AnswerTex ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ t: Does   ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ not need  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ brackets  ┆           ┆           ┆          │\n",
       "│ 1000      ┆ Simplify  ┆ Simplifyi ┆ Simplify  ┆ … ┆ Construct ┆ A         ┆ 1000_A    ┆ 891      │\n",
       "│           ┆ an        ┆ ng        ┆ the follo ┆   ┆ Name:     ┆           ┆           ┆          │\n",
       "│           ┆ algebraic ┆ Algebraic ┆ wing, if  ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆ fraction  ┆ Fractions ┆ possible: ┆   ┆ an        ┆           ┆           ┆          │\n",
       "│           ┆ by factor ┆           ┆ \\( \\frac{ ┆   ┆ algebraic ┆           ┆           ┆          │\n",
       "│           ┆ ising the ┆           ┆ 1-t}{t-1} ┆   ┆ fraction  ┆           ┆           ┆          │\n",
       "│           ┆ numerator ┆           ┆ \\)        ┆   ┆ by factor ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ising the ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ numerator ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ SubjectNa ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ me: Simpl ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ifying    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Algebraic ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Fractions ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ QuestionT ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ext:      ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the follo ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ wing, if  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ possible: ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\( \\frac{ ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1-t}{t-1} ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\) Answer ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Text: \\(  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ t \\)      ┆           ┆           ┆          │\n",
       "│ 1000      ┆ Simplify  ┆ Simplifyi ┆ Simplify  ┆ … ┆ Construct ┆ C         ┆ 1000_C    ┆ 891      │\n",
       "│           ┆ an        ┆ ng        ┆ the follo ┆   ┆ Name:     ┆           ┆           ┆          │\n",
       "│           ┆ algebraic ┆ Algebraic ┆ wing, if  ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆ fraction  ┆ Fractions ┆ possible: ┆   ┆ an        ┆           ┆           ┆          │\n",
       "│           ┆ by factor ┆           ┆ \\( \\frac{ ┆   ┆ algebraic ┆           ┆           ┆          │\n",
       "│           ┆ ising the ┆           ┆ 1-t}{t-1} ┆   ┆ fraction  ┆           ┆           ┆          │\n",
       "│           ┆ numerator ┆           ┆ \\)        ┆   ┆ by factor ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ising the ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ numerator ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ SubjectNa ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ me: Simpl ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ifying    ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Algebraic ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Fractions ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ QuestionT ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ ext:      ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Simplify  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ the follo ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ wing, if  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ possible: ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\( \\frac{ ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1-t}{t-1} ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ \\) Answer ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ Text: \\(  ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 1 \\)      ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainの前処理\n",
    "train_long = preprocess_train(train)\n",
    "train_long.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記の処理はなしでいいかも\n",
    "\n",
    "# # mappingにSubjectNameの情報を追加\n",
    "# mapping = add_subject_name_info(train, mapping)\n",
    "\n",
    "# mapping.head()\n",
    "\n",
    "# # NOTE: submit時は下記のようにtestの情報も使う → これでCVによる学習時と同じ条件になる\n",
    "# # train_test = pl.concat([train, test], how=\"diagonal\")\n",
    "# # mapping = add_subject_name_info(train_test, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retrieval_data(train_long, mapping, model, k):\n",
    "    # 問題文をベクトル化\n",
    "    train_long_vec = model.encode(train_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "\n",
    "    # 誤概念をベクトル化\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "    # misconception_mapping_vec = model.encode(\n",
    "    #     mapping[\"MisconceptionName_with_SubjectNames\"].to_list(), normalize_embeddings=True\n",
    "    # )\n",
    "\n",
    "    # 問題文と誤概念のコサイン類似度を計算\n",
    "    train_cos_sim_arr = cosine_similarity(train_long_vec, misconception_mapping_vec)\n",
    "    # コサイン類似度が高い順にソート\n",
    "    train_sorted_indices = np.argsort(-train_cos_sim_arr, axis=1)\n",
    "\n",
    "    # 各問題に対してk個の予測誤概念IDを追加\n",
    "    train_long = train_long.with_columns(\n",
    "        pl.Series(train_sorted_indices[:, :k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    # 予測誤概念の情報を結合\n",
    "    train_retrieved = (\n",
    "        # 予測誤概念IDリストを展開\n",
    "        train_long.explode(\"PredictMisconceptionId\")\n",
    "        # 正解の誤概念情報を結合\n",
    "        .join(mapping, on=\"MisconceptionId\")\n",
    "        # 予測の誤概念情報を結合(カラム名に\"Predict\"を付与)\n",
    "        .join(mapping.rename(lambda x: \"Predict\" + x), on=\"PredictMisconceptionId\")\n",
    "        # 正解と予測が一致する行を削除\n",
    "        .filter(pl.col(\"MisconceptionId\") != pl.col(\"PredictMisconceptionId\"))\n",
    "    )\n",
    "\n",
    "    return train_retrieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:994: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ../../results/002/20241115_190315/fold1\n",
      "BAAI/bge-large-en-v1.5のfine-tuningを開始します。(1/5fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='1346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 184/1346 08:36 < 54:57, 0.35 it/s, Epoch 0.27/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.680300</td>\n",
       "      <td>1.686817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    }
   ],
   "source": [
    "# 実験結果格納用のディレクトリを作成\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "map_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(\n",
    "    gkf.split(train_long, groups=train_long[\"QuestionId\"], y=train_long[\"SubjectName\"])\n",
    "):\n",
    "    save_dir = os.path.join(cfg.data.results_path, f\"fold{i+1}\")\n",
    "    create_dir(save_dir)\n",
    "\n",
    "    model = SentenceTransformer(cfg.model.model_name)\n",
    "\n",
    "    train_retrieved = make_retrieval_data(train_long[train_idx], mapping, model, cfg.k)\n",
    "    valid_retrieved = make_retrieval_data(train_long[valid_idx], mapping, model, cfg.k)\n",
    "    train_dataset = Dataset.from_polars(train_retrieved)\n",
    "    valid_dataset = Dataset.from_polars(valid_retrieved)\n",
    "    if DEBUG:\n",
    "        train_dataset = train_dataset.select(range(50))\n",
    "        valid_dataset = valid_dataset.select(range(50))\n",
    "    loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "    print(f\"{cfg.model.model_name}のfine-tuningを開始します。({i+1}/{gkf.n_splits}fold)\")\n",
    "\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        output_dir=save_dir,\n",
    "        # Optional training parameters:\n",
    "        num_train_epochs=cfg.model.epoch,\n",
    "        per_device_train_batch_size=cfg.model.batch_size,\n",
    "        gradient_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        per_device_eval_batch_size=cfg.model.batch_size,\n",
    "        eval_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        learning_rate=cfg.model.lr,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=FP,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "        bf16=BF,  # Set to True if you have a GPU that supports BF16\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # no duplicate samples in a batch\n",
    "        # Optional tracking/debugging parameters:\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=0.1,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.1,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"loss\",\n",
    "        greater_is_better=False,\n",
    "        logging_steps=100,\n",
    "        # report_to=REPORT_TO,  # Will be used in W&B if `wandb` is installed\n",
    "        # run_name=EXP_NAME,\n",
    "        do_eval=True,\n",
    "    )\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset.select_columns([\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]),\n",
    "        # train_dataset=train_dataset.select_columns(\n",
    "        #     [\"AllText\", \"MisconceptionName_with_SubjectNames\", \"PredictMisconceptionName_with_SubjectNames\"]\n",
    "        # ),\n",
    "        eval_dataset=valid_dataset.select_columns([\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]),\n",
    "        loss=loss,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(save_dir, create_model_card=False)\n",
    "\n",
    "    # 評価\n",
    "\n",
    "    valid_long = train_long[valid_idx]\n",
    "    # 問題文をベクトル化\n",
    "    valid_long_vec = model.encode(valid_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "    # 誤概念をベクトル化\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "    # 問題文と誤概念のコサイン類似度を計算\n",
    "    valid_cos_sim_arr = cosine_similarity(valid_long_vec, misconception_mapping_vec)\n",
    "    # コサイン類似度が高い順にソート\n",
    "    valid_sorted_indices = np.argsort(-valid_cos_sim_arr, axis=1)\n",
    "    # 各問題に対してk個の予測誤概念IDを追加\n",
    "    valid_long = valid_long.with_columns(\n",
    "        pl.Series(valid_sorted_indices[:, : cfg.k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    actual_misconception_ids = [[mis_id] for mis_id in valid_long[\"MisconceptionId\"].to_list()]\n",
    "    predicted_misconception_ids = valid_long[\"PredictMisconceptionId\"].to_list()\n",
    "    # map@25\n",
    "    map_score = mapk(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    # recall@25\n",
    "    recall_score = recall_at_k(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    recall_scores.append(recall_score)\n",
    "\n",
    "    print(f\"\\n================ fold{i+1} result================\\n\")\n",
    "    print(f\"map@25: {map_score}\")\n",
    "    print(f\"recall@25: {recall_score}\")\n",
    "\n",
    "\n",
    "print(\"\\n================CV result================\\n\")\n",
    "print(f\"map@25: {np.mean(map_scores)}\")\n",
    "print(f\"recall@25: {np.mean(recall_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceにpush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingfaceにpush\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# Hugging Faceのトークンを設定\n",
    "HfFolder.save_token(\"your_huggingface_token\")\n",
    "\n",
    "# 各foldのモデルをプッシュ\n",
    "for fold in range(1, 6):  # 1から5までのfold\n",
    "    save_dir = os.path.join(cfg.data.results_path, f\"fold{fold}\")\n",
    "\n",
    "    # 保存されたモデルを読み込み\n",
    "    model = SentenceTransformer(save_dir)\n",
    "\n",
    "    # モデルをHugging Faceにpush\n",
    "    model.push_to_hub(\n",
    "        f\"marumarukun/{cfg.model.model_name}_fine_tuned_fold{fold}_{cfg.run_time}\",\n",
    "        commit_message=f\"Add fold{fold} SentenceTransformer model\",\n",
    "    )\n",
    "    print(f\"Fold {fold} モデルのプッシュが完了しました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
