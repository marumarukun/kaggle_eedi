{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '002'\n",
      "run_time: base\n",
      "data:\n",
      "  input_root: ../../data/input\n",
      "  train_path: ../../data/input/train.csv\n",
      "  test_path: ../../data/input/test.csv\n",
      "  sample_submission_path: ../../data/input/sample_submission.csv\n",
      "  mapping_path: ../../data/input/misconception_mapping.csv\n",
      "  mapping_meta_path: ../../data/input/mapping_meta.parquet\n",
      "  output_root: ../../data/output\n",
      "  results_root: ../../results\n",
      "  results_path: ../../results/002/base\n",
      "seed: 42\n",
      "k: 25\n",
      "n_splits: 4\n",
      "model:\n",
      "  model_name: BAAI/bge-large-en-v1.5\n",
      "  epoch: 2\n",
      "  lr: 2.0e-05\n",
      "  batch_size: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pytz\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from omegaconf import OmegaConf\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from transformers.trainer_utils import get_last_checkpoint  # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ‘ã‚¹ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "\n",
    "from src.config import cfg\n",
    "from src.data import preprocess_train\n",
    "from src.dir import create_dir\n",
    "from src.metric import mapk, recall_at_k\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(1000)\n",
    "\n",
    "# ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–å¯¾ç­–\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_bf16_supported()=True\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "BOOSTING_NUM = 2\n",
    "FP = False if torch.cuda.is_bf16_supported() else True\n",
    "BF = True if torch.cuda.is_bf16_supported() else False\n",
    "print(f\"{torch.cuda.is_bf16_supported()=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "mapping = pl.read_csv(cfg.data.mapping_path, try_parse_dates=True)\n",
    "\n",
    "# CV\n",
    "gkf = StratifiedGroupKFold(n_splits=cfg.n_splits, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations to carry out calculations involving powers&quot;</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ?&quot;</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;ConstructName: Use the order of operations to carry out calculations involving powers SubjectName: BIDMAS QuestionText: \\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do the brackets need to go to make the answer equal \\( 13 \\) ? AnswerText: Does not need brackets&quot;</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( t \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( t \\)&quot;</td><td>&quot;A&quot;</td><td>&quot;1000_A&quot;</td><td>891</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction by factorising the numerator&quot;</td><td>&quot;Simplifying Algebraic Fractions&quot;</td><td>&quot;Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\)&quot;</td><td>&quot;B&quot;</td><td>&quot;AnswerCText&quot;</td><td>&quot;\\( 1 \\)&quot;</td><td>&quot;ConstructName: Simplify an algebraic fraction by factorising the numerator SubjectName: Simplifying Algebraic Fractions QuestionText: Simplify the following, if possible: \\( \\frac{1-t}{t-1} \\) AnswerText: \\( 1 \\)&quot;</td><td>&quot;C&quot;</td><td>&quot;1000_C&quot;</td><td>891</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 11)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ QuestionI â”† Construct â”† SubjectNa â”† QuestionT â”† â€¦ â”† AllText   â”† AnswerAlp â”† QuestionI â”† Misconce â”‚\n",
       "â”‚ d         â”† Name      â”† me        â”† ext       â”†   â”† ---       â”† habet     â”† d_Answer  â”† ptionId  â”‚\n",
       "â”‚ ---       â”† ---       â”† ---       â”† ---       â”†   â”† str       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ i64       â”† str       â”† str       â”† str       â”†   â”†           â”† str       â”† str       â”† i64      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0         â”† Use the   â”† BIDMAS    â”† \\[        â”† â€¦ â”† Construct â”† D         â”† 0_D       â”† 1672     â”‚\n",
       "â”‚           â”† order of  â”†           â”† 3 \\times  â”†   â”† Name: Use â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† operation â”†           â”† 2+4-5     â”†   â”† the order â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† s to      â”†           â”† \\]        â”†   â”† of operat â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† carry out â”†           â”† Where do  â”†   â”† ions to   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† calculati â”†           â”† the       â”†   â”† carry out â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ons       â”†           â”† brackets  â”†   â”† calculati â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† involving â”†           â”† need to   â”†   â”† ons       â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† powers    â”†           â”† go to     â”†   â”† involving â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† make the  â”†   â”† powers    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† answer    â”†   â”† SubjectNa â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† equal \\(  â”†   â”† me:       â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”† 13 \\) ?   â”†   â”† BIDMAS    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† QuestionT â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ext: \\[   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 3 \\times  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 2+4-5     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\]        â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Where do  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† the       â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† brackets  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† need to   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† go to     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† make the  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† answer    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† equal \\(  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 13 \\) ?   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† AnswerTex â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† t: Does   â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† not need  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† brackets  â”†           â”†           â”†          â”‚\n",
       "â”‚ 1000      â”† Simplify  â”† Simplifyi â”† Simplify  â”† â€¦ â”† Construct â”† A         â”† 1000_A    â”† 891      â”‚\n",
       "â”‚           â”† an        â”† ng        â”† the follo â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† algebraic â”† Algebraic â”† wing, if  â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fraction  â”† Fractions â”† possible: â”†   â”† an        â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† by factor â”†           â”† \\( \\frac{ â”†   â”† algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ising the â”†           â”† 1-t}{t-1} â”†   â”† fraction  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† numerator â”†           â”† \\)        â”†   â”† by factor â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ising the â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† numerator â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† SubjectNa â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† me: Simpl â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ifying    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Fractions â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† QuestionT â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ext:      â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† the follo â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† wing, if  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† possible: â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\( \\frac{ â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 1-t}{t-1} â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\) Answer â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Text: \\(  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† t \\)      â”†           â”†           â”†          â”‚\n",
       "â”‚ 1000      â”† Simplify  â”† Simplifyi â”† Simplify  â”† â€¦ â”† Construct â”† C         â”† 1000_C    â”† 891      â”‚\n",
       "â”‚           â”† an        â”† ng        â”† the follo â”†   â”† Name:     â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† algebraic â”† Algebraic â”† wing, if  â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fraction  â”† Fractions â”† possible: â”†   â”† an        â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† by factor â”†           â”† \\( \\frac{ â”†   â”† algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ising the â”†           â”† 1-t}{t-1} â”†   â”† fraction  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† numerator â”†           â”† \\)        â”†   â”† by factor â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ising the â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† numerator â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† SubjectNa â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† me: Simpl â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ifying    â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Algebraic â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Fractions â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† QuestionT â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† ext:      â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Simplify  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† the follo â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† wing, if  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† possible: â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\( \\frac{ â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 1-t}{t-1} â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† \\) Answer â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† Text: \\(  â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”†           â”†           â”†   â”† 1 \\)      â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainã®å‰å‡¦ç†\n",
    "train_long = preprocess_train(train)\n",
    "train_long.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹è¨˜ã®å‡¦ç†ã¯ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹æ™‚ã¯ãªã—ã§ã„ã„ã‹ã‚‚\n",
    "# æ¨è«–æ™‚ã¯ã‚ã‚Šã‹ã‚‚ã€åŠ¹æœãŒå¦‚ä½•ç¨‹ã‹LBã§æ¤œè¨¼ä¸­\n",
    "\n",
    "# # mappingã«SubjectNameã®æƒ…å ±ã‚’è¿½åŠ \n",
    "# mapping = add_subject_name_info(train, mapping)\n",
    "\n",
    "# mapping.head()\n",
    "\n",
    "# # NOTE: submitæ™‚ã¯ä¸‹è¨˜ã®ã‚ˆã†ã«testã®æƒ…å ±ã‚‚ä½¿ã† â†’ ã“ã‚Œã§CVã«ã‚ˆã‚‹å­¦ç¿’æ™‚ã¨åŒã˜æ¡ä»¶ã«ãªã‚‹ â†’ testã®æƒ…å ±ã¯ä½¿ãˆãªã‹ã£ãŸç¬‘\n",
    "# NOTE:è¿½è¨˜ã€ã‚ãã¾ã§ãƒ¢ãƒ‡ãƒ«å­¦ç¿’æ™‚ã¯ãƒ¡ã‚¿æƒ…å ±ãªã—ã®ã»ã†ãŒç²¾åº¦ãŒé«˜ããªã‚‹ã¨æ€ã‚ã‚Œã‚‹\n",
    "# ãã®æ–¹ãŒé›£ã—ã„å•é¡Œã‚’è§£ã‹ã›ã‚‹ã“ã¨ã«ãªã‚‹ãŸã‚\n",
    "# # train_test = pl.concat([train, test], how=\"diagonal\")\n",
    "# # mapping = add_subject_name_info(train_test, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retrieval_data(train_long, mapping, model, k):\n",
    "    # å•é¡Œæ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    train_long_vec = model.encode(train_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "\n",
    "    # èª¤æ¦‚å¿µã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "\n",
    "    # å•é¡Œæ–‡ã¨èª¤æ¦‚å¿µã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—\n",
    "    train_cos_sim_arr = cosine_similarity(train_long_vec, misconception_mapping_vec)\n",
    "    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ\n",
    "    train_sorted_indices = np.argsort(-train_cos_sim_arr, axis=1)\n",
    "\n",
    "    # å„å•é¡Œã«å¯¾ã—ã¦kå€‹ã®äºˆæ¸¬èª¤æ¦‚å¿µIDã‚’è¿½åŠ \n",
    "    train_long = train_long.with_columns(\n",
    "        pl.Series(train_sorted_indices[:, :k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    # äºˆæ¸¬èª¤æ¦‚å¿µã®æƒ…å ±ã‚’çµåˆ\n",
    "    train_retrieved = (\n",
    "        # äºˆæ¸¬èª¤æ¦‚å¿µIDãƒªã‚¹ãƒˆã‚’å±•é–‹\n",
    "        train_long.explode(\"PredictMisconceptionId\")\n",
    "        # æ­£è§£ã®èª¤æ¦‚å¿µæƒ…å ±ã‚’çµåˆ\n",
    "        .join(mapping, on=\"MisconceptionId\")\n",
    "        # äºˆæ¸¬ã®èª¤æ¦‚å¿µæƒ…å ±ã‚’çµåˆ(ã‚«ãƒ©ãƒ åã«\"Predict\"ã‚’ä»˜ä¸)\n",
    "        .join(mapping.rename(lambda x: \"Predict\" + x), on=\"PredictMisconceptionId\")\n",
    "        # æ­£è§£ã¨äºˆæ¸¬ãŒä¸€è‡´ã™ã‚‹è¡Œã‚’å‰Šé™¤\n",
    "        .filter(pl.col(\"MisconceptionId\") != pl.col(\"PredictMisconceptionId\"))\n",
    "    )\n",
    "\n",
    "    return train_retrieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:994: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ../../results/002/20241117_105432/fold2_boosting_2\n",
      "BAAI/bge-large-en-v1.5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚(2/4fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1232' max='1232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1232/1232 47:27, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.827700</td>\n",
       "      <td>1.848664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>2.009266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.864800</td>\n",
       "      <td>1.979559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>1.742526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.963900</td>\n",
       "      <td>1.735553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>0.807100</td>\n",
       "      <td>1.788621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>0.480500</td>\n",
       "      <td>1.788318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>1.746995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1116</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>1.724299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ fold2 result================\n",
      "\n",
      "map@25: 0.3798299398608819\n",
      "recall@25: 0.7861751152073733\n",
      "Directory created: ../../results/002/20241117_105432/fold3_boosting_2\n",
      "BAAI/bge-large-en-v1.5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚(3/4fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1234' max='1234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1234/1234 47:15, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.828700</td>\n",
       "      <td>1.831863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.705900</td>\n",
       "      <td>1.946421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>1.828819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>1.937602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.000400</td>\n",
       "      <td>1.778428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>0.876400</td>\n",
       "      <td>1.828466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>0.531400</td>\n",
       "      <td>1.909217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>1.814998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1116</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>1.764044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ fold3 result================\n",
      "\n",
      "map@25: 0.40125760088814505\n",
      "recall@25: 0.7752081406105458\n",
      "Directory created: ../../results/002/20241117_105432/fold4_boosting_2\n",
      "BAAI/bge-large-en-v1.5ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚(4/4fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/kaggle_eedi/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1228' max='1228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1228/1228 47:20, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.787800</td>\n",
       "      <td>1.786098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.718700</td>\n",
       "      <td>1.836849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>1.765941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>0.935700</td>\n",
       "      <td>1.820202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>0.969200</td>\n",
       "      <td>1.734533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>0.808900</td>\n",
       "      <td>1.652705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>0.513300</td>\n",
       "      <td>1.734791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>984</td>\n",
       "      <td>0.593800</td>\n",
       "      <td>1.691447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1107</td>\n",
       "      <td>0.625500</td>\n",
       "      <td>1.657104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n",
      "Error while generating model card:                                   \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 1233, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 962, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"ğŸ¤—\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 416, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/huggingface_hub/repocard.py\", line 326, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 889, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/root/kaggle_eedi/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py\", line 434, in set_widget_examples\n",
      "    indices, _ = zip(*sorted(lengths.items(), key=lambda x: x[1]))\n",
      "    ^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ fold4 result================\n",
      "\n",
      "map@25: 0.38074377722429786\n",
      "recall@25: 0.7994530537830447\n",
      "\n",
      "================CV result================\n",
      "\n",
      "map@25: 0.38727710599110826\n",
      "recall@25: 0.7869454365336545\n"
     ]
    }
   ],
   "source": [
    "# å®Ÿé¨“çµæœæ ¼ç´ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "# cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "cfg.run_time = \"20241117_105432\"\n",
    "\n",
    "map_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(\n",
    "    gkf.split(train_long, groups=train_long[\"QuestionId\"], y=train_long[\"SubjectName\"])\n",
    "):\n",
    "    # 2foldç›®ä»¥é™ã‚’å®Ÿè¡Œ\n",
    "    if i == 0:\n",
    "        continue\n",
    "    save_dir = os.path.join(cfg.data.results_path, f\"fold{i+1}_boosting_{BOOSTING_NUM}\")\n",
    "    create_dir(save_dir)\n",
    "\n",
    "    if BOOSTING_NUM == 1:\n",
    "        model = SentenceTransformer(cfg.model.model_name)\n",
    "    else:\n",
    "        model_name = cfg.model.model_name.replace(\"/\", \"-\")\n",
    "        model = SentenceTransformer(\n",
    "            f\"marumarukun/{model_name}_fine_tuned_fold{i+1}_{cfg.run_time}_boosting_{BOOSTING_NUM-1}\"\n",
    "        )\n",
    "\n",
    "    train_retrieved = make_retrieval_data(train_long[train_idx], mapping, model, cfg.k)\n",
    "    valid_retrieved = make_retrieval_data(train_long[valid_idx], mapping, model, cfg.k)\n",
    "    train_dataset = Dataset.from_polars(train_retrieved)\n",
    "    valid_dataset = Dataset.from_polars(valid_retrieved)\n",
    "    if DEBUG:\n",
    "        train_dataset = train_dataset.select(range(50))\n",
    "        valid_dataset = valid_dataset.select(range(50))\n",
    "    loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "    print(f\"{cfg.model.model_name}ã®fine-tuningã‚’é–‹å§‹ã—ã¾ã™ã€‚({i+1}/{gkf.n_splits}fold)\")\n",
    "\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        output_dir=save_dir,\n",
    "        # Optional training parameters:\n",
    "        num_train_epochs=cfg.model.epoch,\n",
    "        per_device_train_batch_size=cfg.model.batch_size,\n",
    "        gradient_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        per_device_eval_batch_size=cfg.model.batch_size,\n",
    "        eval_accumulation_steps=128 // cfg.model.batch_size,\n",
    "        learning_rate=cfg.model.lr,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=FP,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "        bf16=BF,  # Set to True if you have a GPU that supports BF16\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # no duplicate samples in a batch\n",
    "        # Optional tracking/debugging parameters:\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=0.1,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.1,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"loss\",\n",
    "        greater_is_better=False,\n",
    "        logging_steps=100,\n",
    "        # report_to=REPORT_TO,  # Will be used in W&B if `wandb` is installed\n",
    "        # run_name=EXP_NAME,\n",
    "        do_eval=True,\n",
    "    )\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset.select_columns([\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]),\n",
    "        eval_dataset=valid_dataset.select_columns([\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]),\n",
    "        loss=loss,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(save_dir, create_model_card=False)\n",
    "\n",
    "    # è©•ä¾¡\n",
    "\n",
    "    valid_long = train_long[valid_idx]\n",
    "    # å•é¡Œæ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    valid_long_vec = model.encode(valid_long[\"AllText\"].to_list(), normalize_embeddings=True)\n",
    "    # èª¤æ¦‚å¿µã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "    misconception_mapping_vec = model.encode(mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True)\n",
    "    # å•é¡Œæ–‡ã¨èª¤æ¦‚å¿µã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—\n",
    "    valid_cos_sim_arr = cosine_similarity(valid_long_vec, misconception_mapping_vec)\n",
    "    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ\n",
    "    valid_sorted_indices = np.argsort(-valid_cos_sim_arr, axis=1)\n",
    "    # å„å•é¡Œã«å¯¾ã—ã¦kå€‹ã®äºˆæ¸¬èª¤æ¦‚å¿µIDã‚’è¿½åŠ \n",
    "    valid_long = valid_long.with_columns(\n",
    "        pl.Series(valid_sorted_indices[:, : cfg.k].tolist()).alias(\"PredictMisconceptionId\")\n",
    "    )\n",
    "\n",
    "    actual_misconception_ids = [[mis_id] for mis_id in valid_long[\"MisconceptionId\"].to_list()]\n",
    "    predicted_misconception_ids = valid_long[\"PredictMisconceptionId\"].to_list()\n",
    "    # map@25\n",
    "    map_score = mapk(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    # recall@25\n",
    "    recall_score = recall_at_k(actual_misconception_ids, predicted_misconception_ids, k=25)\n",
    "    recall_scores.append(recall_score)\n",
    "\n",
    "    print(f\"\\n================ fold{i+1} result================\\n\")\n",
    "    print(f\"map@25: {map_score}\")\n",
    "    print(f\"recall@25: {recall_score}\")\n",
    "\n",
    "    del model\n",
    "    del trainer\n",
    "    del train_dataset\n",
    "    del valid_dataset\n",
    "    del train_retrieved\n",
    "    del valid_retrieved\n",
    "    del valid_long_vec\n",
    "    del misconception_mapping_vec\n",
    "    del valid_cos_sim_arr\n",
    "    del valid_sorted_indices\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "\n",
    "print(\"\\n================CV result================\\n\")\n",
    "print(f\"map@25: {np.mean(map_scores)}\")\n",
    "print(f\"recall@25: {np.mean(recall_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceã«push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:29<00:00, 46.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:25<00:00, 53.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:25<00:00, 52.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:26<00:00, 49.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "# huggingfaceã«push\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# Hugging Faceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š\n",
    "HfFolder.save_token(\"your_hf_token\")\n",
    "\n",
    "# å„foldã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒƒã‚·ãƒ¥\n",
    "for i in range(cfg.n_splits):\n",
    "    fold = i + 1\n",
    "    save_dir = os.path.join(cfg.data.results_path, f\"fold{fold}_boosting_{BOOSTING_NUM}\")\n",
    "\n",
    "    # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
    "    model = SentenceTransformer(save_dir)\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤\n",
    "    model_name = cfg.model.model_name.replace(\"/\", \"-\")\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’Hugging Faceã«push\n",
    "    model.push_to_hub(\n",
    "        f\"marumarukun/{model_name}_fine_tuned_fold{fold}_{cfg.run_time}_boosting_{BOOSTING_NUM}\",\n",
    "        commit_message=f\"Add fold{fold} SentenceTransformer model\",\n",
    "    )\n",
    "    print(f\"Fold {fold} ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒƒã‚·ãƒ¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
